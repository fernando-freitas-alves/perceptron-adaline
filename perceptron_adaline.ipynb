{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "This notebook shows the implementation of a perceptron in Python, which structure illustrated bellow.\n",
    "\n",
    "<center><img src=\"resources/img/perceptron.png\" alt=\"Perceptron\" width=\"500px\"/></center>\n",
    "\n",
    "Some datasets are evaluated and the results are discussed in the following cells. The main idea is to show in a 2D figure the distringuishing approch of a perception, illustration the lines that separates two classes of a dataset, has illustrated bellow in a 3D surface.\n",
    "\n",
    "<center><img src=\"resources/img/linear_classifier.png\" alt=\"Separation line of a linear classifier\" width=\"500px\"/></center>\n",
    "\n",
    "Before we start, it is useful to define some functions first.\n",
    "\n",
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy        import array, hstack, inner, isscalar, mean, ndim, repeat, shape, squeeze, transpose, vstack, zeros\n",
    "from numpy.random import MT19937, RandomState, SeedSequence\n",
    "\n",
    "msqr             = lambda a: mean(inner(a,a))  # mean square\n",
    "ndims            = lambda a: shape(a)[1];      # number of dimensions\n",
    "nelems           = lambda a: shape(a)[0];      # number of elements\n",
    "new_random_state = lambda seed=123: RandomState(MT19937(SeedSequence(seed)))\n",
    "\n",
    "random_state = new_random_state()\n",
    "\n",
    "# # Inser a column to a given 2D matrix at specified index\n",
    "# def insert_column(X, column=[], index=-1):\n",
    "#     nd = ndim(X)\n",
    "#     if nd == 0:\n",
    "#         n = 1\n",
    "#         m = 1\n",
    "#     elif nd == 1:\n",
    "#         n = 1\n",
    "#         m = len(X)\n",
    "#     else:\n",
    "#         n, m = X.shape\n",
    "#     Y   = zeros((n, m + 1))\n",
    "#     rng = list(range(m + 1))\n",
    "#     if index == -1:\n",
    "#         I = array(rng[0:index])\n",
    "#     else:\n",
    "#         I = array(rng[0:index] + rng[index+1:m+1])\n",
    "#     Y[:,I] = X\n",
    "#     if isscalar(column):\n",
    "#         Y[:,index] = column\n",
    "#     elif len(column) != 0:\n",
    "#         Y[:,index] = squeeze(column)\n",
    "#     if n == 1:\n",
    "#         Y = Y[0]\n",
    "#     return Y\n",
    "\n",
    "def display(matrix, nrows=-1):\n",
    "    if ndim(matrix) <= 1:\n",
    "        matrix = transpose([matrix])\n",
    "    if nrows == 0:\n",
    "        submatrix = []\n",
    "    elif nrows == -1:\n",
    "        submatrix = matrix\n",
    "    elif nrows < -1:\n",
    "        submatrix = matrix[:nrows+1,:]\n",
    "    else:\n",
    "        submatrix = matrix[:nrows,:]\n",
    "    if shape(submatrix) == shape(matrix):\n",
    "        out = matrix\n",
    "    else:\n",
    "        n    = ndims(matrix)\n",
    "        dots = repeat(['...'], n)\n",
    "        end  = matrix[-1,:]\n",
    "        out  = vstack((submatrix, dots, end))\n",
    "    print(out)\n",
    "\n",
    "def display_data(inputs, labels, nrows=-1):\n",
    "    matrix = hstack([inputs, transpose([labels])])\n",
    "    display(matrix, nrows)\n",
    "\n",
    "# Uniform random between a and b\n",
    "def urand(a, b, *args, **kwargs):\n",
    "    r   = random_state.rand(*args, **kwargs)\n",
    "    rab = (b - a) * r + a\n",
    "    return rab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import array, loadtxt, transpose\n",
    "from numpy import loadtxt\n",
    "\n",
    "def load_data1(filename):\n",
    "    data   = loadtxt(filename)\n",
    "    inputs = data[:,0:2]\n",
    "    labels = data[:,2] - 1\n",
    "    return inputs, labels\n",
    "\n",
    "def load_data2(filename):\n",
    "    pass\n",
    "\n",
    "def load_data3(filename):\n",
    "    data   = loadtxt(filename, delimiter=';')\n",
    "    inputs = data[:,1]\n",
    "    labels = data[:,0]\n",
    "    return transpose([inputs]), labels\n",
    "#     return [inputs], labels\n",
    "\n",
    "def keep_only_labels(inputs, labels, labels_to_keep):\n",
    "    selected_inputs = array([x.tolist() for x, y in zip(inputs, labels) if y in labels_to_keep])\n",
    "    selected_labels = array([y for y in labels if y in labels_to_keep])\n",
    "    return selected_inputs, selected_labels\n",
    "\n",
    "def keep_only_labels2(inputs, labels):\n",
    "    labels_to_keep                   = unique(labels)[0:2] # only first two labels\n",
    "    selected_inputs, selected_labels = keep_only_labels(inputs, labels, labels_to_keep)\n",
    "    return selected_inputs, selected_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron base class\n",
    "This cells implements a base neuron class that can be used with eighter a perceptron, an ADALINE or even any other similar structure with a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy        import append, full, insert, ones, ones_like, sign, unique, where\n",
    "from numpy.random import permutation\n",
    "\n",
    "class Neuron():\n",
    "    def __init__(self, input_length, learning_rate=0.01, max_epochs=1e2, min_loss=1e-2):\n",
    "        self.input_length  = int(input_length)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs    = int(max_epochs)\n",
    "        self.min_loss      = min_loss\n",
    "        self.weights       = self.__initialize_weight__(length=input_length+1)\n",
    "\n",
    "        # Propertiers defined elsewhere\n",
    "        self.iterations    = None\n",
    "        self.epochs        = None\n",
    "        self.inputs        = None\n",
    "        self.labels        = None\n",
    "        self.losses        = None\n",
    "        self.unique_labels = None\n",
    "\n",
    "    def __adapt__(self, input, error, iteration=-1):\n",
    "        w = self.weights[iteration]\n",
    "        n = self.learning_rate\n",
    "        new_weight   = w + n*input*error # adaptation rule\n",
    "        self.weights = append(self.weights, [new_weight], axis=0)\n",
    "\n",
    "    def __calc_cost__(self, errors):\n",
    "        cost = msqr(errors) # mean square error\n",
    "        return cost\n",
    "\n",
    "    def __calc_error__(self, labels, outputs):\n",
    "        diff   = labels - outputs\n",
    "        errors = sign(diff)\n",
    "        return errors\n",
    "\n",
    "    def __converged__(self, iteration=-1):\n",
    "        if len(self.losses) > 0:\n",
    "            converged = self.losses[iteration] <= self.min_loss # convergence rule\n",
    "        else:\n",
    "            converged = False\n",
    "        return converged\n",
    "\n",
    "    def __expand_inputs__(self, inputs):\n",
    "        num_inputs      = nelems(inputs)\n",
    "        biases          = -ones((1, num_inputs))\n",
    "        expanded_inputs = insert(inputs, 0, biases, axis=1)\n",
    "        return expanded_inputs\n",
    "\n",
    "    def __initialize_weight__(self, length):\n",
    "        w0 = urand(-1, 1, length)\n",
    "#         w0 = [-0.6270591 ,  1.96598375, -1.89546286]\n",
    "        return [w0]\n",
    "\n",
    "    def __predict__(self, input, iteration=-1):\n",
    "        weights       = self.weights[iteration]\n",
    "        inner_state   = inner(weights, input) # induced local field\n",
    "        neuron_output = self.__activation_function__(inner_state)\n",
    "        output        = self.__translate_output__(neuron_output)\n",
    "        return output.tolist()\n",
    "\n",
    "    def predict(self, input, iteration=-1):\n",
    "        expanded_input = self.__expand_inputs__(input)\n",
    "        output         = self.__predict__(expanded_input, iteration)\n",
    "        return output\n",
    "\n",
    "    def train(self, inputs, labels, shuffle_data=False):\n",
    "        def prepare_training(inputs, labels, shuffle_data):\n",
    "            self.inputs         = inputs\n",
    "            self.labels         = labels\n",
    "            self.unique_labels  = unique(labels)\n",
    "            self.num_inputs     = nelems(inputs)\n",
    "            self.max_iterations = self.num_inputs*(self.max_epochs + 1) + 1\n",
    "            self.losses         = []\n",
    "            expanded_inputs     = self.__expand_inputs__(inputs)\n",
    "            if shuffle_data:\n",
    "                permutations    = permutation(self.num_inputs) # random shuffle\n",
    "                expanded_inputs = expanded_inputs[permutations]\n",
    "                self.inputs     = self.inputs[permutations]\n",
    "                self.labels     = self.labels[permutations]\n",
    "            return expanded_inputs, self.labels\n",
    "\n",
    "        def finish_training(iteration):\n",
    "            self.iterations = iteration\n",
    "            self.epochs     = int(iteration/self.num_inputs) + 1\n",
    "\n",
    "        expanded_inputs, labels = prepare_training(inputs, labels, shuffle_data)\n",
    "        # Calculate loss with all inputs (for initial weights)\n",
    "        outputs = self.__predict__(expanded_inputs)\n",
    "        errors  = self.__calc_error__(labels, outputs)\n",
    "        self.losses.append(self.__calc_cost__(errors))\n",
    "        # Train loop\n",
    "        iteration = 0\n",
    "        while not self.__converged__() and iteration < self.max_iterations:\n",
    "            for input, label in zip(expanded_inputs, labels):\n",
    "                # Adapt with given input\n",
    "                output = self.__predict__(input)\n",
    "                error  = self.__calc_error__(label, output)\n",
    "                self.__adapt__(input, error)\n",
    "                iteration += 1\n",
    "                # Calculate loss with all inputs (this can be moved to outside of the loop for efficiency)\n",
    "                outputs = self.__predict__(expanded_inputs)\n",
    "                errors  = self.__calc_error__(labels, outputs)\n",
    "                self.losses.append(self.__calc_cost__(errors))\n",
    "                if self.__converged__() or iteration == self.max_iterations: break # taking advantage of iteration-based neuron\n",
    "        finish_training(iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron class\n",
    "The Percetron class then inherits the base Neuron class and implements its out activation and output translation functions.\n",
    "\n",
    "The function `kernel` is useful to determine the separation line between two classes.\n",
    "\n",
    "The function `predict` is overloaded to process the input if any adaptation is required beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(Neuron):\n",
    "    def __activation_function__(self, inner_state):\n",
    "        act_fcn = where(inner_state < 0, 0, 1) # all-or-none\n",
    "        return act_fcn\n",
    "\n",
    "    def __translate_output__(self, neuron_output):\n",
    "        classes = self.unique_labels\n",
    "        output  = where(neuron_output <= 0, classes[0], classes[1])\n",
    "        return output\n",
    "\n",
    "    def kernel(self, input_class1=None, input_class2=None, iteration=-1):\n",
    "        weight = self.weights[iteration]\n",
    "        if input_class1 is None:\n",
    "            input_class1 = []\n",
    "            for x in input_class2:\n",
    "                input  = self.__expand_inputs__([[0, x]])\n",
    "                weight = -weight/weight[1]\n",
    "                input_class1.append(inner(weight, input)[0])\n",
    "            return input_class1\n",
    "        elif input_class2 is None:\n",
    "            input_class2 = []\n",
    "            for x in input_class1:\n",
    "                input  = self.__expand_inputs__([[x, 0]])\n",
    "                weight = -weight/weight[2]\n",
    "                input_class2.append(inner(weight, input)[0])\n",
    "            return input_class2\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def predict(self, input, iteration=-1):\n",
    "        if ndim(input) == 1:\n",
    "            input = [input]\n",
    "        return super().predict(input, iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaline classes\n",
    "The Adaline classes also inherits the base Neuron class and implements its out activation, output translation, kernel and predict functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear ADALINE\n",
    "This Adaline class implements a first order ADALINE regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline1(Neuron):\n",
    "    def __activation_function__(self, inner_state):\n",
    "        act_fcn = inner_state\n",
    "        return act_fcn\n",
    "\n",
    "    def __translate_output__(self, neuron_output):\n",
    "        output = neuron_output\n",
    "        return output\n",
    "\n",
    "#     def kernel(self, partial_input, missing_dimension, iteration=-1):\n",
    "#         weight       = self.weights[iteration]\n",
    "#         input_kernel = []\n",
    "#         for row in partial_input:\n",
    "#             input           = insert_column(row, index=missing_dimension)\n",
    "#             expanded_input  = self.__expand_inputs__([input])\n",
    "#             relative_weight = -weight/weight[missing_dimension]\n",
    "#             inner_state     = inner(relative_weight, input)\n",
    "#             if not isscalar(inner_state):\n",
    "#                 inner_state = inner_state[0]\n",
    "#             input_kernel.append(inner_state)\n",
    "#         return input_kernel\n",
    "\n",
    "    def predict(self, input, iteration=-1):\n",
    "        if isscalar(input):\n",
    "            input = transpose([[input]])\n",
    "            output = super().predict(input, iteration)[0]\n",
    "            return output\n",
    "        if ndim(input) == 1:\n",
    "            input = transpose([input])\n",
    "        output = super().predict(input, iteration)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd-order ADALINE\n",
    "This Adaline class implements a second order ADALINE regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline2(Neuron):\n",
    "    def __activation_function__(self, inner_state):\n",
    "        act_fcn = inner_state\n",
    "        return act_fcn\n",
    "\n",
    "    def __translate_output__(self, neuron_output):\n",
    "        output = neuron_output\n",
    "        return output\n",
    "\n",
    "#     def kernel(self, partial_input, missing_dimension, iteration=-1):\n",
    "#         weight       = self.weights[iteration]\n",
    "#         input_kernel = []\n",
    "#         for row in partial_input:\n",
    "#             input           = insert_column(row, index=missing_dimension)\n",
    "#             expanded_input  = self.__expand_inputs__([input])\n",
    "#             relative_weight = -weight/weight[missing_dimension]\n",
    "#             inner_state     = inner(relative_weight, input)\n",
    "#             if not isscalar(inner_state):\n",
    "#                 inner_state = inner_state[0]\n",
    "#             input_kernel.append(inner_state)\n",
    "#         return input_kernel\n",
    "\n",
    "    def predict(self, input, iteration=-1):\n",
    "        def raise_order(input):\n",
    "            input = insert(input, 1, values=transpose(input**2), axis=1)\n",
    "            return input\n",
    "\n",
    "        if isscalar(input):\n",
    "            input = transpose([[input]])\n",
    "            input = raise_order(input)\n",
    "            output = super().predict(input, iteration)[0]\n",
    "            return output\n",
    "        if ndim(input) == 1:\n",
    "            input = transpose([input])\n",
    "        if ndims(input) == 1:\n",
    "            input = raise_order(input)\n",
    "        output = super().predict(input, iteration)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure class\n",
    "The following class can look complex, but it is composed by a set of functions that process the neuron output and convergence, illustrating the results in epochs.\n",
    "\n",
    "For the reader interested in the perceptron itself, this cell can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.io       import output_notebook\n",
    "from bokeh.layouts  import column, row\n",
    "from bokeh.models   import ColumnDataSource, CustomJS, LinearAxis, Range1d, Slider, tickers\n",
    "from bokeh.plotting import Figure, output_file, show\n",
    "from numpy          import argsort, array, concatenate, sort\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "class Figure_classification():\n",
    "    def __init__(self, neuron, width=400, height=400):\n",
    "        self.neuron = neuron\n",
    "        self.__init_plot_params__()\n",
    "\n",
    "        [fig1, area_left, area_right] = self.__create_figure1__()\n",
    "        fig2   = self.__create_figure2__()\n",
    "        slider = self.__create_slider__(area_left, area_right)\n",
    "        if slider is None:\n",
    "            self.layout = row(fig1, fig2)\n",
    "        else:\n",
    "            self.layout = column(slider, row(fig1, fig2))\n",
    "\n",
    "    def __create_figure1__(self, width=400, height=400):\n",
    "        figure     = Figure(plot_width=width, plot_height=height)\n",
    "        colors_lr  = self.source1_weights.tags[2][-1]\n",
    "        area_left  = figure.varea(x='x', y1='y1_left',  y2='y2_left',  source=self.source1_weights, fill_color=colors_lr[0], fill_alpha=0.2)\n",
    "        area_right = figure.varea(x='x', y1='y1_right', y2='y2_right', source=self.source1_weights, fill_color=colors_lr[1], fill_alpha=0.2)\n",
    "        for class_input, legend_label, color in zip(self.class_input, self.legend_labels, self.colors):\n",
    "            x = class_input[:,0]\n",
    "            y = class_input[:,1]\n",
    "            c = figure.circle(x, y, size=10, fill_color=color, fill_alpha=0.6, line_color=None, legend_label=legend_label)\n",
    "        figure.line('x', 'y', source=self.source1_weights, line_width=3, line_alpha=0.6, line_color='black')\n",
    "        figure.circle('x', 'y', source=self.source1_selection, size=10, fill_color=None, line_color='black', line_alpha=0.6, line_width=3)\n",
    "        # Properties\n",
    "        figure.x_range = self.x_range\n",
    "        figure.y_range = self.y_range\n",
    "        figure.legend.click_policy = 'hide'\n",
    "        return figure, area_left, area_right\n",
    "\n",
    "    def __create_figure2__(self, width=400, height=400):\n",
    "        figure = Figure(plot_width=width, plot_height=height, x_axis_label='Iteration', y_axis_label='Loss')\n",
    "        # Iteration axis\n",
    "        x_iteration = self.source2_iteration.data['x']\n",
    "        y_iteration = self.source2_iteration.data['y']\n",
    "        figure.line(x_iteration, y_iteration, line_width=3, line_color='black', line_alpha=0.1)\n",
    "        figure.line('x', 'y', source=self.source2_iteration, line_width=3, line_color='black', legend_label='Iteration loss')\n",
    "        # Epoch axis\n",
    "        x_epoch = self.source2_epoch.data['x']\n",
    "        y_epoch = self.source2_epoch.data['y']\n",
    "        color_epoch = 'red'\n",
    "        figure.extra_x_ranges = {'epoch': Range1d(start=0, end=self.neuron.epochs)}\n",
    "        figure.line(x_epoch, y_epoch, x_range_name='epoch', line_width=3, line_color=color_epoch, line_alpha=0.1)\n",
    "        figure.line('x', 'y', source=self.source2_epoch, x_range_name='epoch', line_width=3, line_color=color_epoch, legend_label='Epoch loss')\n",
    "        figure.add_layout(LinearAxis(x_range_name           = 'epoch',\n",
    "                                     axis_label             = 'Epoch',\n",
    "                                     axis_label_text_color  = color_epoch,\n",
    "                                     axis_line_color        = color_epoch,\n",
    "                                     major_label_text_color = color_epoch,\n",
    "                                     major_tick_line_color  = color_epoch,\n",
    "                                     minor_tick_line_color  = color_epoch),\n",
    "                          'above')\n",
    "        # Properties\n",
    "        if min(x_iteration) != max(x_iteration):\n",
    "            figure.x_range = Range1d(min(x_iteration), max(x_iteration), bounds=\"auto\")\n",
    "        else:\n",
    "            figure.x_range = Range1d(min(x_iteration), max(x_iteration) + 1, bounds=\"auto\")\n",
    "        figure.y_range = Range1d(0, max(y_iteration) + 1, bounds=\"auto\")\n",
    "        figure.xaxis.ticker.min_interval = 1\n",
    "        figure.yaxis.ticker.min_interval = 1\n",
    "        figure.xaxis.ticker.num_minor_ticks = 0\n",
    "        figure.yaxis.ticker.num_minor_ticks = 0\n",
    "        figure.legend.click_policy = 'hide'\n",
    "        return figure\n",
    "\n",
    "    def __create_slider__(self, area_left, area_right):\n",
    "        if self.neuron.iterations == 0:\n",
    "            return None\n",
    "        else:\n",
    "            callback1_weights = CustomJS(args=dict(area_left=area_left, area_right=area_right, source=self.source1_weights), code=\"\"\"\n",
    "                var i                       = cb_obj.value\n",
    "                var x1_span                 = source.tags[0][i]\n",
    "                var x2_span                 = source.tags[1][i]\n",
    "                var colors_lr               = source.tags[2][i]\n",
    "                var x2_span_s               = x2_span.slice().sort()\n",
    "                source.data['x']            = x1_span\n",
    "                source.data['y']            = x2_span\n",
    "                source.data['y1_left']      = [x2_span_s[0], x2_span[1]]\n",
    "                source.data['y2_left']      = [x2_span_s[1], x2_span[1]]\n",
    "                source.data['y1_right']     = [x2_span[0],   x2_span_s[0]]\n",
    "                source.data['y2_right']     = [x2_span[0],   x2_span_s[1]]\n",
    "                area_left.glyph.fill_color  = colors_lr[0]\n",
    "                area_right.glyph.fill_color = colors_lr[1]\n",
    "                source.change.emit()\n",
    "            \"\"\")\n",
    "            callback1_selection = CustomJS(args=dict(source=self.source1_selection), code=\"\"\"\n",
    "                var i            = cb_obj.value\n",
    "                var X            = source.tags[0]\n",
    "                var Y            = source.tags[1]\n",
    "                source.data['x'] = [X[i % X.length]]\n",
    "                source.data['y'] = [Y[i % Y.length]]\n",
    "                source.change.emit()\n",
    "            \"\"\")\n",
    "            callback2_iteration = CustomJS(args=dict(source=self.source2_iteration), code=\"\"\"\n",
    "                var i            = cb_obj.value\n",
    "                var x            = source.tags[0].slice(0, i + 1)\n",
    "                var y            = source.tags[1].slice(0, i + 1)\n",
    "                source.data['x'] = x\n",
    "                source.data['y'] = y\n",
    "                source.change.emit()\n",
    "            \"\"\")\n",
    "            callback2_epoch = CustomJS(args=dict(source=self.source2_epoch), code=\"\"\"\n",
    "                var i    = cb_obj.value\n",
    "                var end  = cb_obj.end\n",
    "                var base = source.tags[2]\n",
    "                if (i !== end)\n",
    "                {\n",
    "                    var e = Math.floor(i / base)\n",
    "                }\n",
    "                else\n",
    "                {\n",
    "                    var e = Math.ceil(i / base)\n",
    "                }\n",
    "                var x            = source.tags[0].slice(0, e + 1)\n",
    "                var y            = source.tags[1].slice(0, e + 1)\n",
    "                source.data['x'] = x\n",
    "                source.data['y'] = y\n",
    "                source.change.emit()\n",
    "            \"\"\")\n",
    "            slider = Slider(start=0, end=self.neuron.iterations, value=self.neuron.iterations, step=1, title='Iteration')\n",
    "            slider.js_on_change('value', callback1_weights)\n",
    "            slider.js_on_change('value', callback1_selection)\n",
    "            slider.js_on_change('value', callback2_iteration)\n",
    "            slider.js_on_change('value', callback2_epoch)\n",
    "            return slider\n",
    "\n",
    "    def __init_plot_params__(self):\n",
    "        n  = self.neuron.input_length\n",
    "        k  = self.neuron.num_inputs\n",
    "        X  = self.neuron.inputs\n",
    "        Y  = self.neuron.labels\n",
    "        C  = self.neuron.unique_labels\n",
    "        W  = self.neuron.weights\n",
    "        I  = range(0, self.neuron.iterations+1)\n",
    "        E  = range(0, self.neuron.epochs+1)\n",
    "        L  = self.neuron.losses\n",
    "        LE = L[::k]\n",
    "        LE.append(L[-1])\n",
    "        self.colors        = ['blue', 'red']\n",
    "        self.legend_labels = ['Class ' + str(int(label)) for label in self.neuron.unique_labels]\n",
    "        x1min, x1max = min(X[:,0]), max(X[:,0])\n",
    "        x2min, x2max = min(X[:,1]), max(X[:,1])\n",
    "        dx1,   dx2   = x1max - x1min, x2max - x2min\n",
    "        x1_range     = [x1min - 0.1*dx1, x1max + 0.1*dx1]\n",
    "        x2_range     = [x2min - 0.1*dx2, x2max + 0.1*dx2]\n",
    "        X1_span      = []\n",
    "        X2_span      = []\n",
    "        colors_lr    = []\n",
    "        for iteration in I:\n",
    "            x1_span = array(x1_range)\n",
    "            x2_span = array(self.neuron.kernel(input_class1=x1_span, iteration=iteration))\n",
    "            i       = argsort(x2_span)\n",
    "            if x2_span[i[0]] > x2_range[0] or x2_span[i[1]] < x2_range[1]:\n",
    "                if x2_span[i[0]] > x2_range[0]:\n",
    "                    x2_span[i[0]] = x2_range[0]\n",
    "                if x2_span[i[1]] < x2_range[1]:\n",
    "                    x2_span[i[1]] = x2_range[1]\n",
    "                x1_span = array(self.neuron.kernel(input_class2=x2_span, iteration=iteration))\n",
    "            X1_span.append(x1_span)\n",
    "            X2_span.append(x2_span)\n",
    "            input_left   = [x1_span[0] - 1, x2_span[0]]\n",
    "            input_right  = [x1_span[0] + 1, x2_span[0]]\n",
    "            output_left  = self.neuron.predict(input=input_left,  iteration=iteration)\n",
    "            output_right = self.neuron.predict(input=input_right, iteration=iteration)\n",
    "            if output_left < output_right:\n",
    "                color_left  = self.colors[0]\n",
    "                color_right = self.colors[1]\n",
    "            else:\n",
    "                color_left  = self.colors[1]\n",
    "                color_right = self.colors[0]\n",
    "            colors_lr.append([color_left, color_right])\n",
    "        x2_span_s              = sort(x2_span)\n",
    "        self.class_input       = (array([x for x, y in zip(X, Y) if y == c]) for c in C)\n",
    "        self.source1_weights   = ColumnDataSource(data=dict(x        = x1_span,                    y        = x2_span,\n",
    "                                                            y1_left  = [x2_span_s[0], x2_span[1]], y2_left  = [x2_span_s[1], x2_span[1]],\n",
    "                                                            y1_right = [x2_span[0], x2_span_s[0]], y2_right = [x2_span[0], x2_span_s[1]]),\n",
    "                                                            tags     = [X1_span, X2_span, colors_lr])\n",
    "        self.source1_selection = ColumnDataSource(data=dict(x=[X[-1,0]], y=[X[-1,1]]), tags=[X[:,0], X[:,1]])\n",
    "        self.source2_iteration = ColumnDataSource(data=dict(x=I, y=L), tags=[[i for i in I], L])\n",
    "        self.source2_epoch     = ColumnDataSource(data=dict(x=E, y=LE), tags=[[e for e in E], LE, k])\n",
    "        self.x_range           = Range1d(*x1_range, bounds=\"auto\")\n",
    "        self.y_range           = Range1d(*x2_range, bounds=\"auto\")\n",
    "\n",
    "    def show(self):\n",
    "        show(self.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Figure_regression():\n",
    "    def __init__(self, neuron, width=400, height=400):\n",
    "        self.neuron = neuron\n",
    "        self.__init_plot_params__()\n",
    "\n",
    "#         [fig1, area_left, area_right] = self.__create_figure1__()\n",
    "#         fig2   = self.__create_figure2__()\n",
    "#         slider = self.__create_slider__(area_left, area_right)\n",
    "#         if slider is None:\n",
    "#             self.layout = row(fig1, fig2)\n",
    "#         else:\n",
    "#             self.layout = column(slider, row(fig1, fig2))\n",
    "        fig1 = self.__create_figure1__()\n",
    "        slider = self.__create_slider__()\n",
    "        if slider is None:\n",
    "            self.layout = fig1\n",
    "        else:\n",
    "            self.layout = column(slider, fig1)\n",
    "\n",
    "    def __create_figure1__(self, width=400, height=400):\n",
    "#         colors_lr  = self.source1_weights.tags[2][-1]\n",
    "        figure     = Figure(plot_width=width, plot_height=height)\n",
    "#         area_left  = figure.varea(x='x', y1='y1_left',  y2='y2_left',  source=self.source1_weights, fill_color=colors_lr[0], fill_alpha=0.2)\n",
    "#         area_right = figure.varea(x='x', y1='y1_right', y2='y2_right', source=self.source1_weights, fill_color=colors_lr[1], fill_alpha=0.2)\n",
    "#         for class_input, legend_label, color in zip(self.class_input, self.legend_labels, self.colors):\n",
    "#             x = class_input[:,0]\n",
    "#             y = class_input[:,1]\n",
    "#             c = figure.circle(x, y, size=10, fill_color=color, fill_alpha=0.6, line_color=None, legend_label=legend_label)\n",
    "        figure.line('x', 'y', source=self.source1, line_width=3, line_alpha=0.6, line_color='black', legend_label='Input')\n",
    "        figure.line('x', 'yi', source=self.source1, line_width=3, line_alpha=0.6, line_color='red', legend_label='Output')\n",
    "#         figure.circle('x', 'y', source=self.source1_selection, size=10, fill_color=None, line_color='black', line_alpha=0.6, line_width=3)\n",
    "        # Properties\n",
    "        figure.x_range = self.x_range\n",
    "        figure.y_range = self.y_range\n",
    "        figure.legend.click_policy = 'hide'\n",
    "#         return figure, area_left, area_right\n",
    "        return figure\n",
    "\n",
    "#     def __create_figure2__(self, width=400, height=400):\n",
    "#         figure = Figure(plot_width=width, plot_height=height, x_axis_label='Iteration', y_axis_label='Loss')\n",
    "#         # Iteration axis\n",
    "#         x_iteration = self.source2_iteration.data['x']\n",
    "#         y_iteration = self.source2_iteration.data['y']\n",
    "#         figure.line(x_iteration, y_iteration, line_width=3, line_color='black', line_alpha=0.1)\n",
    "#         figure.line('x', 'y', source=self.source2_iteration, line_width=3, line_color='black', legend_label='Iteration loss')\n",
    "#         # Epoch axis\n",
    "#         x_epoch = self.source2_epoch.data['x']\n",
    "#         y_epoch = self.source2_epoch.data['y']\n",
    "#         color_epoch = 'red'\n",
    "#         figure.extra_x_ranges = {'epoch': Range1d(start=0, end=self.neuron.epochs)}\n",
    "#         figure.line(x_epoch, y_epoch, x_range_name='epoch', line_width=3, line_color=color_epoch, line_alpha=0.1)\n",
    "#         figure.line('x', 'y', source=self.source2_epoch, x_range_name='epoch', line_width=3, line_color=color_epoch, legend_label='Epoch loss')\n",
    "#         figure.add_layout(LinearAxis(x_range_name           = 'epoch',\n",
    "#                                      axis_label             = 'Epoch',\n",
    "#                                      axis_label_text_color  = color_epoch,\n",
    "#                                      axis_line_color        = color_epoch,\n",
    "#                                      major_label_text_color = color_epoch,\n",
    "#                                      major_tick_line_color  = color_epoch,\n",
    "#                                      minor_tick_line_color  = color_epoch),\n",
    "#                           'above')\n",
    "#         # Properties\n",
    "#         if min(x_iteration) != max(x_iteration):\n",
    "#             figure.x_range = Range1d(min(x_iteration), max(x_iteration), bounds=\"auto\")\n",
    "#         else:\n",
    "#             figure.x_range = Range1d(min(x_iteration), max(x_iteration) + 1, bounds=\"auto\")\n",
    "#         figure.y_range = Range1d(0, max(y_iteration) + 1, bounds=\"auto\")\n",
    "#         figure.xaxis.ticker.min_interval = 1\n",
    "#         figure.yaxis.ticker.min_interval = 1\n",
    "#         figure.xaxis.ticker.num_minor_ticks = 0\n",
    "#         figure.yaxis.ticker.num_minor_ticks = 0\n",
    "#         figure.legend.click_policy = 'hide'\n",
    "#         return figure\n",
    "\n",
    "    def __create_slider__(self):\n",
    "        if self.neuron.iterations == 0:\n",
    "            return None\n",
    "        else:\n",
    "            callback1 = CustomJS(args=dict(source=self.source1), code=\"\"\"\n",
    "                var i             = cb_obj.value\n",
    "                var yi            = source.tags[0][i]\n",
    "                source.data['yi'] = yi\n",
    "                source.change.emit()\n",
    "            \"\"\")\n",
    "#             callback1_selection = CustomJS(args=dict(source=self.source1_selection), code=\"\"\"\n",
    "#                 var i            = cb_obj.value\n",
    "#                 var X            = source.tags[0]\n",
    "#                 var Y            = source.tags[1]\n",
    "#                 source.data['x'] = [X[i % X.length]]\n",
    "#                 source.data['y'] = [Y[i % Y.length]]\n",
    "#                 source.change.emit()\n",
    "#             \"\"\")\n",
    "#             callback2_iteration = CustomJS(args=dict(source=self.source2_iteration), code=\"\"\"\n",
    "#                 var i            = cb_obj.value\n",
    "#                 var x            = source.tags[0].slice(0, i + 1)\n",
    "#                 var y            = source.tags[1].slice(0, i + 1)\n",
    "#                 source.data['x'] = x\n",
    "#                 source.data['y'] = y\n",
    "#                 source.change.emit()\n",
    "#             \"\"\")\n",
    "#             callback2_epoch = CustomJS(args=dict(source=self.source2_epoch), code=\"\"\"\n",
    "#                 var i    = cb_obj.value\n",
    "#                 var end  = cb_obj.end\n",
    "#                 var base = source.tags[2]\n",
    "#                 if (i !== end)\n",
    "#                 {\n",
    "#                     var e = Math.floor(i / base)\n",
    "#                 }\n",
    "#                 else\n",
    "#                 {\n",
    "#                     var e = Math.ceil(i / base)\n",
    "#                 }\n",
    "#                 var x            = source.tags[0].slice(0, e + 1)\n",
    "#                 var y            = source.tags[1].slice(0, e + 1)\n",
    "#                 source.data['x'] = x\n",
    "#                 source.data['y'] = y\n",
    "#                 source.change.emit()\n",
    "#             \"\"\")\n",
    "#             slider = Slider(start=0, end=3, value=3, step=1, title='Iteration')\n",
    "            slider = Slider(start=0, end=self.neuron.iterations, value=self.neuron.iterations, step=1, title='Iteration')\n",
    "            slider.js_on_change('value', callback1)\n",
    "#             slider.js_on_change('value', callback1_selection)\n",
    "#             slider.js_on_change('value', callback2_iteration)\n",
    "#             slider.js_on_change('value', callback2_epoch)\n",
    "            return slider\n",
    "\n",
    "    def __init_plot_params__(self):\n",
    "#         n  = self.neuron.input_length\n",
    "#         k  = self.neuron.num_inputs\n",
    "        X  = self.neuron.inputs\n",
    "        Y  = self.neuron.labels\n",
    "        Xt = transpose(X)[0]\n",
    "#         print('X',X)\n",
    "#         print('Xt',Xt)\n",
    "#         C  = self.neuron.unique_labels\n",
    "#         W  = self.neuron.weights\n",
    "        I  = range(0, self.neuron.iterations+1)\n",
    "#         I  = range(0, self.neuron.iterations+1)[0:3]\n",
    "#         E  = range(0, self.neuron.epochs+1)\n",
    "#         L  = self.neuron.losses\n",
    "#         LE = L[::k]\n",
    "#         LE.append(L[-1])\n",
    "\n",
    "#         self.colors        = ['blue', 'red']\n",
    "#         self.legend_labels = ['Class ' + str(int(label)) for label in self.neuron.unique_labels]\n",
    "\n",
    "        xmin, xmax = min(Xt), max(Xt)\n",
    "        ymin, ymax = min(Y), max(Y)\n",
    "        dy         = ymax - ymin\n",
    "        x_range    = [xmin, xmax]\n",
    "        y_range    = [ymin - 0.1*dy, ymax + 0.1*dy]\n",
    "#         X1_span      = []\n",
    "#         X2_span      = []\n",
    "#         colors_lr    = []\n",
    "#         for iteration in I:\n",
    "#             x1_span = array(x1_range)\n",
    "#             x2_span = array(self.neuron.kernel(input_class1=x1_span, iteration=iteration))\n",
    "#             i       = argsort(x2_span)\n",
    "#             if x2_span[i[0]] > x2_range[0] or x2_span[i[1]] < x2_range[1]:\n",
    "#                 if x2_span[i[0]] > x2_range[0]:\n",
    "#                     x2_span[i[0]] = x2_range[0]\n",
    "#                 if x2_span[i[1]] < x2_range[1]:\n",
    "#                     x2_span[i[1]] = x2_range[1]\n",
    "#                 x1_span = array(self.neuron.kernel(input_class2=x2_span, iteration=iteration))\n",
    "#             X1_span.append(x1_span)\n",
    "#             X2_span.append(x2_span)\n",
    "        YI = []\n",
    "        for iteration in I:\n",
    "            yi = array(self.neuron.predict(X, iteration=iteration))\n",
    "            YI.append(yi)\n",
    "\n",
    "#             input_left   = [x1_span[0] - 1, x2_span[0]]\n",
    "#             input_right  = [x1_span[0] + 1, x2_span[0]]\n",
    "#             output_left  = self.neuron.predict(input=input_left,  iteration=iteration)\n",
    "#             output_right = self.neuron.predict(input=input_right, iteration=iteration)\n",
    "\n",
    "#             if output_left < output_right:\n",
    "#                 color_left  = self.colors[0]\n",
    "#                 color_right = self.colors[1]\n",
    "#             else:\n",
    "#                 color_left  = self.colors[1]\n",
    "#                 color_right = self.colors[0]\n",
    "#             colors_lr.append([color_left, color_right])\n",
    "#         x2_span_s = sort(x2_span)\n",
    "\n",
    "#         self.class_input       = (array([x for x, y in zip(X, Y) if y == c]) for c in C)\n",
    "        self.source1 = ColumnDataSource(data=dict(x=Xt, y=Y, yi=YI[-1]), tags=[YI])\n",
    "#         self.source1_selection = ColumnDataSource(data=dict(x=[X[-1,0]], y=[X[-1,1]]), tags=[X[:,0], X[:,1]])\n",
    "#         self.source2_iteration = ColumnDataSource(data=dict(x=I, y=L), tags=[[i for i in I], L])\n",
    "#         self.source2_epoch     = ColumnDataSource(data=dict(x=E, y=LE), tags=[[e for e in E], LE, k])\n",
    "        self.x_range = Range1d(*x_range, bounds=\"auto\")\n",
    "        self.y_range = Range1d(*y_range, bounds=\"auto\")\n",
    "\n",
    "    def show(self):\n",
    "        show(self.layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ADALINE and plot results\n",
    "The dataset for ADALINE is a long list of number pairs.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs3_1, labels3_1 = load_data3('./datasets/item 3/dataset_regression.csv')\n",
    "display_data(inputs3_1, labels3_1, nrows=3)\n",
    "\n",
    "adaline3_1 = Adaline1(input_length=ndims(inputs3_1), learning_rate=0.001, max_epochs=1e2)\n",
    "adaline3_1.train(inputs3_1, labels3_1)\n",
    "\n",
    "figure3_1 = Figure_regression(adaline3_1)\n",
    "figure3_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs3_2 = insert(inputs3_1, 1, values=transpose(inputs3_1**2), axis=1)\n",
    "# labels3_2 = labels3_1\n",
    "# display_data(inputs3_2, labels3_2, nrows=3)\n",
    "inputs3_1, labels3_1 = inputs3_2, labels3_2\n",
    "\n",
    "adaline3_2 = Adaline2(input_length=ndims(inputs3_2), learning_rate=0.001, max_epochs=1e2)\n",
    "adaline3_2.train(inputs3_2, labels3_2)\n",
    "\n",
    "display_data(adaline3_2.inputs, adaline3_2.labels, nrows=3)\n",
    "\n",
    "figure3_2 = Figure_regression(adaline3_2)\n",
    "figure3_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adaline3_2.labels)\n",
    "adaline3_2.predict(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit(\"Stop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train perceptron and plot results\n",
    "## Dataset 1\n",
    "In this dataset, the perceptron was able to converge pretty quickly with the following dataset.\n",
    "The adaptation rule lead to the maximum minimum. That is because the dataset has classes quick separated from each other.\n",
    "\n",
    "Note that the learning rate does not need to be quite small. One can play with the parameters, like the learning rate and maximum epochs to check different results. It can be seen that with greater learning rates, the perceptron is able to converge and faster with this dataset.\n",
    "\n",
    "_(Hint: the iteration slider can be controlled by the keyboard.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1_1, labels1_1 = load_data1('./datasets/item 1/dataset1.txt')\n",
    "inputs1_1, labels1_1 = keep_only_labels2(inputs1_1, labels1_1)\n",
    "display_data(inputs1_1, labels1_1, nrows=3)\n",
    "\n",
    "perceptron1_1 = Perceptron(input_length=ndims(inputs1_1), learning_rate=0.001, max_epochs=5e2)\n",
    "perceptron1_1.train(inputs1_1, labels1_1)\n",
    "\n",
    "figure1_1 = Figure_classification(perceptron1_1)\n",
    "figure1_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2\n",
    "This time, the dataset variance overlaps on the classes. That means points from one class can mix with points from other classes.\n",
    "Since the perceptron can only separate classes linearly, the algorithm was not able to converge, stopping only after reaching the maximum number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1_2, labels1_2 = load_data1('./datasets/item 1/dataset2.txt')\n",
    "inputs1_2, labels1_2 = keep_only_labels2(inputs1_2, labels1_2)\n",
    "display_data(inputs1_2, labels1_2, nrows=3)\n",
    "\n",
    "perceptron1_2 = Perceptron(input_length=ndims(inputs1_2), learning_rate=0.0001, max_epochs=2000)\n",
    "perceptron1_2.train(inputs1_2, labels1_2)\n",
    "\n",
    "figure1_2 = Figure_classification(perceptron1_2)\n",
    "figure1_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3\n",
    "This dataset has concurrent classes mean positions and variances. The overlap and non-linearity of the data lead to an oscillating results, forbiding the perceptron to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1_3, labels1_3 = load_data1('./datasets/item 1/dataset3.txt')\n",
    "inputs1_3, labels1_3 = keep_only_labels2(inputs1_3, labels1_3)\n",
    "display_data(inputs1_3, labels1_3, nrows=3)\n",
    "\n",
    "perceptron1_3 = Perceptron(input_length=ndims(inputs1_3), learning_rate=0.001)\n",
    "perceptron1_3.train(inputs1_3, labels1_3)\n",
    "\n",
    "figure1_3 = Figure_classification(perceptron1_3)\n",
    "figure1_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 4\n",
    "This dataset has a data disposition similar to the previous one, but with higher variance. Again, the overlap and non-linearity of the data lead to an oscillating results, forbiding the perceptron to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1_4, labels1_4 = load_data1('./datasets/item 1/dataset4.txt')\n",
    "inputs1_4, labels1_4 = keep_only_labels2(inputs1_4, labels1_4)\n",
    "display_data(inputs1_4, labels1_4, nrows=3)\n",
    "\n",
    "perceptron1_4 = Perceptron(input_length=ndims(inputs1_4), learning_rate=0.001)\n",
    "perceptron1_4.train(inputs1_4, labels1_4)\n",
    "\n",
    "figure1_4 = Figure_classification(perceptron1_4)\n",
    "figure1_4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 5\n",
    "This time, the dataset almost overlap, but the perceptron was able to converge, within given maximum number of epochs, since a linear separation of the dataset is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1_5, labels1_5 = load_data1('./datasets/item 1/dataset5.txt')\n",
    "inputs1_5, labels1_5 = keep_only_labels2(inputs1_5, labels1_5)\n",
    "display_data(inputs1_5, labels1_5, nrows=3)\n",
    "\n",
    "perceptron1_5 = Perceptron(input_length=ndims(inputs1_5), learning_rate=0.001, max_epochs=5e2)\n",
    "perceptron1_5.train(inputs1_5, labels1_5, shuffle_data=True)\n",
    "\n",
    "figure1_5 = Figure_classification(perceptron1_5)\n",
    "figure1_5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 6\n",
    "The following data has a similar disposition from the last one, but with higher spreadness. The result separation from the perceptron tried to find the best position between the centroids of both classes. However, it got stuck in near a local minimum solution, oscillating in loss due to the variance of both classes.\n",
    "\n",
    "What is interesting to notice is that after around 300 epochs, the oscillation in loss increased. That demonstrate the instability of the perceptron to keep stuck around a local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1_6, labels1_6 = load_data1('./datasets/item 1/dataset6.txt')\n",
    "inputs1_6, labels1_6 = keep_only_labels2(inputs1_6, labels1_6)\n",
    "display_data(inputs1_6, labels1_6, nrows=3)\n",
    "\n",
    "perceptron1_6 = Perceptron(input_length=ndims(inputs1_6), learning_rate=0.001, max_epochs=5e2)\n",
    "perceptron1_6.train(inputs1_6, labels1_6, shuffle_data=True)\n",
    "\n",
    "figure1_6 = Figure_classification(perceptron1_6)\n",
    "figure1_6.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
